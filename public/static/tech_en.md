1. Z-Works Interview
   (1) Self Introduction
2. Tech Stack (Current)
   2.1 Full Stack
   2.2 Frontend

JavaScript / React (State Management: useState, useRef, useEffect)

WebSocket (Connection, event emit, optimizing bandwidth for real-time data transmission)

Vue (Converted from React-based implementation)

Dart (Similar to Java / C# / C++) and React Native — both translatable from React (similar to iOS Swift structure)

Computational Complexity Optimization (Avoiding O(N²) or higher designs, e.g., nested loops)

Error Handling (Beyond API level; systematic try-except design)

Unit Testing (Testing numeric ranges, types, logic, and exception handling)

UI/UX Design (Google Material Design, color theory—palette/contrast, accessibility: font sizes, A/B testing, prototyping in Cursor; prefer Noto Sans font)

2.3 Backend

Flask (User system, JWT token/session management, RESTful API: GET/POST/DELETE)

MySQL (and PostgreSQL support; experience with data search, migration, and relational ontology design)

Docker (Environment version-control consistency)

Nginx (Routing TCP/IP protocols from domain name provider; bandwidth control)

Redis (Caching to reduce repeated computation and server load)

Third-party API integration

Node.js and MongoDB experience

i18n (JSON-based dictionary internationalization)

2.4 Infrastructure / Logistics

AWS (EC2, RDS, ECS — load balancing planned but not deployed yet)

GitHub (Git workflows: add/commit/push/fetch/pull across local laptop and EC2 Ubuntu instance)

Cloudflare (Caching, DDoS protection, web-scraping prevention)

Google Analytics / Web Traffic Recording

2.5 Machine Learning

Traditional “ready-to-use” algorithms:

XGBoost / CatBoost / Bagging / Ensemble learning (model performance comparison)

Python: scikit-learn + optimized inference libraries

Data mining: Agglomerative clustering, KNN, manifold learning (Kernel PCA), etc.

Deep Learning:

Pretrained inference models: CNN / RCNN / U-Net / ResNet / Transformer (PyTorch; regression/classification)

Custom training using PyTorch

Computer vision: YOLO fine-tuning (object detection on video datasets)

LLM Application and Downstream Tasks:

Prompt Engineering (scientific iteration approach)

RAG (Retrieval-Augmented Generation: LangChain, etc.)

LLM fine-tuning: Llama 3.2 (1B/7B)

AI agent deployment (self-hosted DeepSeek-R1 recommended)

AI API Tools Used:

Sonic (best real-time streaming translation API)

ElevenLabs (voice cloning + TTS/STS)

DeepInfra (LLM inference API)

2.6 Digital Signal Processing

Raw time-series preprocessing: PCA, ICA, Low-pass IIR filters, Short-Time Fourier Transform, Mel-spectrogram

2.7 General Engineering Skills

Cursor / LaTeX / Unix System / Vim / Git / Arduino

Pointer-based languages (C/C++)

Unity (C#)

Project management: Gantt diagrams, OKR, KPI

PRD documentation

3. Additional Contributions Beyond Technical Skills
   3.1 U.S. Research Resources

Stanford Professors Takako Fujioka & Bruce McCandliss — Stanford School of Medicine (IRB access and connections)

Academic publishing, technical writing, and internal research seminars

Applying evidence-based biometrics to healthcare prediction and prevention

Writing healthcare-related blogs

3.2 U.S. Venture Capital Network

Stanford Professor Richard Dasher

Silicon Valley AI-focused investment network

3.3 Business Skills

B2B sales and B2C marketing experience

3.4 China Mainland Industry Network

Hospitals: My mother previously served as a manager at Shenzhen Children's Hospital (now retired)

Venture Capital: Connections with ZhenFund and KaikaiHuaCai (Elder Healthcare Institute, CEO network)

My Perspective on AgeTech and Healthcare AI

I believe AgeTech is extremely meaningful. When I first arrived in Japan, I researched "幸せ tech" (well-being technology), inspired by Apple Vision Pro and how immersive computing enables elderly or disabled individuals to re-experience activities they can no longer physically access.

During my time at Stanford, I presented an analysis of Airweave — a smart bed company using AI to monitor sleep and sync metrics to a mobile app. Recently, I also observed the rise of AI agents in home-care systems receiving seed-round funding in Silicon Valley. I am passionate about the future of AgeTech.

My Perspective on LiveConnect

LiveConnect currently operates as an integrated system capable of detecting contactless behavioral and indirect physiological signals. It also functions as a copilot for a human-in-the-loop cybernetic workflow (for example, supporting nurses).

Future improvements could include expanding multimodal sensing and cognitive-level features — such as personalized voice agents (e.g., using a family member’s voice for emotional support), Apple Vision Pro immersive experiences, and additional adaptive care features.
